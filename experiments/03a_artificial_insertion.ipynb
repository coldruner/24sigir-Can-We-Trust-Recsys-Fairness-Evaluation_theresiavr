{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('HR@5', 0.0114416476),\n",
       "             ('MRR@5', 0.0048436308),\n",
       "             ('P@5', 0.0027459954),\n",
       "             ('MAP@5', 0.0038100686),\n",
       "             ('R@5', 0.0065217391),\n",
       "             ('NDCG@5', 0.0049453202),\n",
       "             ('Jain_ori@5', 0.0296141164),\n",
       "             ('Jain_our@5', 0.0240014145),\n",
       "             ('QF_ori@5', 0.1731984829),\n",
       "             ('QF_our@5', 0.1679389313),\n",
       "             ('Ent_ori@5', nan),\n",
       "             ('Ent_our@5', 0.4135509317),\n",
       "             ('Gini_ori@5', 0.9589900106),\n",
       "             ('Gini_our@5', 0.9626232664),\n",
       "             ('FSat_ori@5', 0.1226295828),\n",
       "             ('FSat_our@5', 0.1170483461),\n",
       "             ('IAA_true_ori@5', 0.0081393364),\n",
       "             ('MME_ori@5', 0.001812438),\n",
       "             ('II-F_ori@5', 0.005343732),\n",
       "             ('AI-F_ori@5', 0.0008316934),\n",
       "             ('IBO_ori@5', nan),\n",
       "             ('IWO_ori@5', nan),\n",
       "             ('IBO_our@5', 0.023923445),\n",
       "             ('IWO_our@5', 0.976076555),\n",
       "             ('IFD_div@5', 0.00250613),\n",
       "             ('IFD_mul@5', 1.1688e-05),\n",
       "             ('HD@5', 0.6111783109)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"sliding/result_Amazon-lb_NCL_at5_1-6.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.evaluator.evaluator import Evaluator\n",
    "    \n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert most fair and relevant (total $km$ items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_items_not_in_rec(u, incoming_k_items, curr_rec):\n",
    "    mask = ~torch.isin(incoming_k_items[u],curr_rec[u])\n",
    "    return incoming_k_items[u][mask]\n",
    "\n",
    "def get_remaining_items(u, all_item_id, curr_rec, rel_not_in_rec):\n",
    "    mask = ~torch.isin(all_item_id, curr_rec[u])\n",
    "    item_not_in_rec = all_item_id[mask]\n",
    "    \n",
    "    mask_rel_not_in_rec = ~torch.isin(item_not_in_rec, rel_not_in_rec[u])\n",
    "    remaining_items = item_not_in_rec[mask_rel_not_in_rec]\n",
    "    return remaining_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 users, 10000 items, and k=10\n",
      "Inserting fair and rel items for all users at 9\n",
      "tensor([[    1,     2,     3,  ...,  9998,  9999, 10000],\n",
      "        [    1,     2,     3,  ...,    17,    18,    19],\n",
      "        [    1,     2,     3,  ...,    27,    28,    29],\n",
      "        ...,\n",
      "        [    1,     2,     3,  ...,  9977,  9978,  9979],\n",
      "        [    1,     2,     3,  ...,  9987,  9988,  9989],\n",
      "        [    1,     2,     3,  ...,  9997,  9998,  9999]])\n",
      "OrderedDict([('HR@10', 1.0), ('MRR@10', 0.1009), ('P@10', 0.1009), ('MAP@10', 0.01099), ('R@10', 0.1009), ('NDCG@10', 0.0645571674), ('Jain_ori@10', 0.0011109877), ('Jain_our@10', 0.0001110988), ('QF_ori@10', 0.1009), ('QF_our@10', 0.1), ('Ent_ori@10', nan), ('Ent_our@10', 0.1), ('Gini_ori@10', 0.98901), ('Gini_our@10', 0.99), ('FSat_ori@10', 0.1009), ('FSat_our@10', 0.1), ('IAA_true_ori@10', 0.001499), ('MME_ori@10', 0.0009897171), ('II-F_ori@10', 0.0004614034), ('AI-F_ori@10', 0.0002725764), ('IBO_ori@10', 0.1009), ('IWO_ori@10', 0.8991), ('IBO_our@10', 0.1009), ('IWO_our@10', 0.8991), ('IFD_div@10', 0.0193237069), ('IFD_mul@10', 1.71936e-05), ('HD@10', 0.2704725741)])\n",
      "total time taken:  2697.261897087097\n",
      "Inserting fair and rel items for all users at 8\n",
      "tensor([[    1,     2,     3,  ...,  9998,  9999, 10000],\n",
      "        [    1,     2,     3,  ...,    16,    17,    18],\n",
      "        [    1,     2,     3,  ...,    26,    27,    28],\n",
      "        ...,\n",
      "        [    1,     2,     3,  ...,  9976,  9977,  9978],\n",
      "        [    1,     2,     3,  ...,  9986,  9987,  9988],\n",
      "        [    1,     2,     3,  ...,  9996,  9997,  9998]])\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "for num_user in [\n",
    "   1000,  \n",
    "]:\n",
    "\n",
    "    num_item = (num_user * k) \n",
    "    all_item_id = torch.arange(num_item) + 1\n",
    "\n",
    "    print(f\"There are {num_user} users, {num_item} items, and k={k}\")\n",
    "\n",
    "    #initialize user-k recommendation matrix by recommending the same k items to all users\n",
    "    same_k_items = np.arange(k)+1 #item index starts from 1\n",
    "    curr_rec = np.tile(same_k_items, (num_user,1))\n",
    "    curr_rec = torch.Tensor(curr_rec).int()\n",
    "\n",
    "    incoming_k_items = np.arange(num_item).reshape(num_user,k) + 1\n",
    "    incoming_k_items = torch.Tensor(incoming_k_items).int()\n",
    "\n",
    "    #initialize user-item_at_k relevance matrix (all irrelevant)\n",
    "    curr_rel = torch.zeros(num_user,k+1,dtype=torch.int32) #+1 because recbole saves number of rel items at the last column\n",
    "    curr_rel[0, :-1] = 1 #first user already has relevant item\n",
    "    curr_rel[:,-1] = k #each user has exactly k relevant items\n",
    "\n",
    "    incoming_k_relevance = torch.ones(num_user,k)\n",
    "\n",
    "    #take struct from a dataset\n",
    "    dataset = \"Amazon-lb\" \n",
    "    model_name = \"Pop\"\n",
    "    list_file = os.listdir(\"../struct/\")\n",
    "    file_for_dataset = [x for x in list_file if dataset in x]\n",
    "    assert len(file_for_dataset) == 1\n",
    "\n",
    "    with open(\"../struct/\"+file_for_dataset[0],\"rb\") as f:\n",
    "        struct = pickle.load(f)\n",
    "\n",
    "    config = Config(\n",
    "                    model=model_name, \n",
    "                    dataset=dataset, \n",
    "                    config_file_list=[\"../RecBole/recbole/properties/overall.yaml\"],\n",
    "                    config_dict={\n",
    "                        \"topk\":k,\n",
    "                        \"metrics\":[\n",
    "                                \"RelMetrics\",\n",
    "                                \"FairWORel\",\n",
    "                                \"IAAinsert\",\n",
    "                                \"MME_IIF_AIF\",\n",
    "                                \"IBO_IWO\",\n",
    "                                \"IFDrerank\",\n",
    "                                \"HD\"    \n",
    "                                ]}\n",
    "                                )\n",
    "\n",
    "    evaluator = Evaluator(config)\n",
    "    struct.set(\"data.num_items\", num_item+1) #because -1 in metrics.py\n",
    "    struct.set(\"rec.items\", curr_rec)\n",
    "    struct.set(\"rec.topk\", curr_rel)\n",
    "    struct.set(\"rec.score\",torch.empty((num_user, num_item+1))) #needed for IAArerank, +1 to add a dummy col for pred_rel (pred_rel only taken from 1: onwards)\n",
    "    struct.set(\"data.pos_items\", incoming_k_items.numpy()) #incoming items are also the only relevant items, but numpy datatype\n",
    "\n",
    "    rel_not_in_rec = [get_rel_items_not_in_rec(u, incoming_k_items, curr_rec) for u, _ in enumerate(incoming_k_items)]\n",
    "    remaining_items = [get_remaining_items(u, all_item_id, curr_rec, rel_not_in_rec) for u, _ in enumerate(curr_rec)]\n",
    "    full_rec_mat = torch.stack([torch.cat([curr_rec[u],remaining_items[u],rel_not_in_rec[u]]) for u, _ in enumerate(curr_rec)])\n",
    "    struct.set(\"rec.all_items\", full_rec_mat)\n",
    "\n",
    "    insertion_result = dict()\n",
    "    result = evaluator.evaluate(struct)\n",
    "    insertion_result[\"0\"] =  result\n",
    "    with open(f'artificial_insertion/fair_user_{str(num_user).zfill(4)}_exact_km_0.pickle', 'wb') as f:\n",
    "        pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    for pos_rank in range(k-1,-1, -1):\n",
    "        print(f\"Inserting fair and rel items for all users at {pos_rank}\")\n",
    "        curr_rec[:,pos_rank] = incoming_k_items[:,pos_rank]\n",
    "        curr_rel[:,pos_rank] = incoming_k_relevance[:,pos_rank]\n",
    "\n",
    "        struct.set(\"rec.items\", curr_rec)\n",
    "        struct.set(\"rec.topk\", curr_rel)\n",
    "\n",
    "        #for IAA and IFD that needs full ranking\n",
    "        rel_not_in_rec = [get_rel_items_not_in_rec(u, incoming_k_items, curr_rec) for u, _ in enumerate(incoming_k_items)]\n",
    "        remaining_items = [get_remaining_items(u, all_item_id, curr_rec, rel_not_in_rec) for u, _ in enumerate(curr_rec)]\n",
    "        full_rec_mat = torch.stack([torch.cat([curr_rec[u],remaining_items[u],rel_not_in_rec[u]]) for u, _ in enumerate(curr_rec)])\n",
    "        struct.set(\"rec.all_items\", full_rec_mat)\n",
    "        print(full_rec_mat)\n",
    "  \n",
    "        start_time = time.time()\n",
    "        result = evaluator.evaluate(struct)\n",
    "        print(result)\n",
    "        print(\"total time taken: \", time.time() - start_time)\n",
    "        \n",
    "        insertion_result[f\"{k-pos_rank}\"] = result\n",
    "\n",
    "        #dump/save per posrank\n",
    "        with open(f'artificial_insertion/fair_user_{str(num_user).zfill(4)}_exact_km_{k-pos_rank}.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(f'artificial_insertion/fair_user_{str(num_user).zfill(4)}_exact_km.pickle', 'wb') as f:\n",
    "        pickle.dump(insertion_result, f, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairreceval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe0d571e343c00b66bb6a6b9f25fbc50947e8e28daf577955b94753bab898243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
